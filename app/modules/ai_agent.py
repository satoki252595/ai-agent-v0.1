# -*- coding: utf-8 -*-
"""
æ—¥æœ¬æ ªãƒªã‚µãƒ¼ãƒAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
å…¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’çµ±åˆã—ãŸAIåˆ†æã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
"""
import streamlit as st
from typing import Dict, List, Optional, Generator
from langchain_ollama import ChatOllama
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from duckduckgo_search import DDGS
import trafilatura
from tenacity import retry, stop_after_attempt, wait_fixed
import os

# è¨­å®š
OLLAMA_URL = st.secrets.get("OLLAMA_BASE_URL", os.environ.get("OLLAMA_BASE_URL", "http://localhost:11435"))
MODEL_NAME = st.secrets.get("MODEL_NAME", os.environ.get("MODEL_NAME", "nemotron-3-nano"))
LLM_TEMPERATURE = 0.3


class StockResearchAgent:
    """æ—¥æœ¬æ ªãƒªã‚µãƒ¼ãƒAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"""

    def __init__(self):
        self.llm = self._get_llm()

    def _get_llm(self):
        """LLMã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—"""
        return ChatOllama(
            model=MODEL_NAME,
            base_url=OLLAMA_URL,
            temperature=LLM_TEMPERATURE,
            headers={"ngrok-skip-browser-warning": "true"},
            keep_alive="5m"
        )

    @retry(stop=stop_after_attempt(3), wait=wait_fixed(2))
    def search_web(self, query: str, max_results: int = 5) -> List[Dict]:
        """Webæ¤œç´¢ã‚’å®Ÿè¡Œ"""
        try:
            with DDGS() as ddgs:
                results = list(ddgs.text(query, region='jp-jp', safesearch='off', max_results=max_results))
            return results
        except Exception as e:
            print(f"Search Error: {e}")
            return []

    def fetch_content(self, url: str) -> str:
        """URLã‹ã‚‰æœ¬æ–‡ã‚’æŠ½å‡º"""
        if url.lower().endswith('.pdf'):
            return ""
        downloaded = trafilatura.fetch_url(url)
        if downloaded is None:
            return ""
        text = trafilatura.extract(downloaded, include_comments=False, include_tables=True)
        return text if text else ""

    def generate_stock_report(
        self,
        ticker: str,
        company_name: str,
        technical_data: Dict,
        fundamental_data: Dict,
        macro_data: Dict,
        news_data: Dict,
        patent_data: Dict = None,
        alpha_signal: Dict = None
    ) -> Generator[str, None, None]:
        """
        ç·åˆæ ªå¼åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼‰
        """
        data_summary = self._create_data_summary(
            ticker, company_name, technical_data, fundamental_data,
            macro_data, news_data, patent_data, alpha_signal
        )

        prompt = ChatPromptTemplate.from_template("""
ã‚ãªãŸã¯æ—¥æœ¬æ ªå°‚é–€ã®ä¸€æµã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã€æŠ•è³‡å®¶å‘ã‘ã®åŒ…æ‹¬çš„ãªãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ã€åˆ†æå¯¾è±¡ã€‘
éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰: {ticker}
ä¼æ¥­å: {company_name}

ã€åé›†ãƒ‡ãƒ¼ã‚¿ã€‘
{data_summary}

ã€ãƒ¬ãƒãƒ¼ãƒˆå½¢å¼ã€‘
# {company_name}ï¼ˆ{ticker}ï¼‰æŠ•è³‡åˆ†æãƒ¬ãƒãƒ¼ãƒˆ

## ğŸ“Š æŠ•è³‡åˆ¤æ–­ã‚µãƒãƒªãƒ¼
- **ç·åˆè©•ä¾¡**: [å¼·ã„è²·ã„/è²·ã„/ä¸­ç«‹/å£²ã‚Š/å¼·ã„å£²ã‚Š]
- **ç›®æ¨™æ ªä¾¡**: [åˆ†æã«åŸºã¥ãç›®æ¨™æ ªä¾¡]
- **ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«**: [ä½/ä¸­/é«˜]

## ğŸ“ˆ ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«åˆ†æ
ï¼ˆç§»å‹•å¹³å‡ã€RSIã€MACDã€ä¸€ç›®å‡è¡¡è¡¨ãªã©ã®åˆ†æçµæœã‚’è¨˜è¼‰ï¼‰

## ğŸ’° ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºåˆ†æ
ï¼ˆãƒãƒªãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã€åç›Šæ€§ã€è²¡å‹™å¥å…¨æ€§ã€æˆé•·æ€§ã®åˆ†æã‚’è¨˜è¼‰ï¼‰

## ğŸŒ ãƒã‚¯ãƒ­ç’°å¢ƒå½±éŸ¿
ï¼ˆç‚ºæ›¿ã€é‡‘åˆ©ã€å¸‚å ´ç’°å¢ƒãŒå½“è©²éŠ˜æŸ„ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’åˆ†æï¼‰

## ğŸ“° ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ»ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆ
ï¼ˆæœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¨ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ†æã®çµæœã‚’è¨˜è¼‰ï¼‰

## ğŸ”¬ æŠ€è¡“åŠ›ãƒ»ç‰¹è¨±å‹•å‘
ï¼ˆç‰¹è¨±ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã¨æŠ€è¡“é©æ–°åŠ›ã®è©•ä¾¡ï¼‰

## âš ï¸ ãƒªã‚¹ã‚¯è¦å› 
ï¼ˆæŠ•è³‡ã«ãŠã‘ã‚‹ä¸»è¦ãªãƒªã‚¹ã‚¯ã‚’åˆ—æŒ™ï¼‰

## ğŸ’¡ æŠ•è³‡æˆ¦ç•¥ææ¡ˆ
ï¼ˆå…·ä½“çš„ãªã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã€æåˆ‡ã‚Šãƒ©ã‚¤ãƒ³ã‚’ææ¡ˆï¼‰

---
â€»æœ¬ãƒ¬ãƒãƒ¼ãƒˆã¯æƒ…å ±æä¾›ã‚’ç›®çš„ã¨ã—ã¦ãŠã‚Šã€æŠ•è³‡åŠ©è¨€ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚
æŠ•è³‡åˆ¤æ–­ã¯è‡ªå·±è²¬ä»»ã§ãŠé¡˜ã„ã„ãŸã—ã¾ã™ã€‚

å¿…ãšæ—¥æœ¬èªã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
""")

        chain = prompt | self.llm | StrOutputParser()

        for chunk in chain.stream({
            "ticker": ticker,
            "company_name": company_name,
            "data_summary": data_summary
        }):
            yield chunk

    def _create_data_summary(
        self,
        ticker: str,
        company_name: str,
        technical_data: Dict,
        fundamental_data: Dict,
        macro_data: Dict,
        news_data: Dict,
        patent_data: Dict = None,
        alpha_signal: Dict = None
    ) -> str:
        """åˆ†æãƒ‡ãƒ¼ã‚¿ã®ã‚µãƒãƒªãƒ¼ã‚’ä½œæˆ"""
        summary_parts = []

        # ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿
        if technical_data:
            tech_summary = f"""
ã€ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™ã€‘
- ç·åˆã‚·ã‚°ãƒŠãƒ«: {technical_data.get('overall_signal', 'N/A')}
- ã‚¹ã‚³ã‚¢: {technical_data.get('score', 'N/A')}
- è²·ã„ã‚·ã‚°ãƒŠãƒ«æ•°: {technical_data.get('buy_signals', 0)}
- å£²ã‚Šã‚·ã‚°ãƒŠãƒ«æ•°: {technical_data.get('sell_signals', 0)}
"""
            if 'signals' in technical_data:
                for signal in technical_data['signals'][:5]:
                    tech_summary += f"- {signal.indicator}: {signal.signal} ({signal.description})\n"
            summary_parts.append(tech_summary)

        # ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ãƒ‡ãƒ¼ã‚¿
        if fundamental_data:
            fund_summary = f"""
ã€ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºã€‘
- ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚¹ã‚³ã‚¢: {fundamental_data.get('fundamental_score', 'N/A')}/100
- ã‚°ãƒ¬ãƒ¼ãƒ‰: {fundamental_data.get('fundamental_grade', 'N/A')}
- PER: {fundamental_data.get('valuation', {}).get('per', 'N/A')}
- PBR: {fundamental_data.get('valuation', {}).get('pbr', 'N/A')}
- ROE: {fundamental_data.get('profitability', {}).get('roe', 'N/A')}
- é…å½“åˆ©å›ã‚Š: {fundamental_data.get('dividend', {}).get('dividend_yield', 'N/A')}
- å£²ä¸Šæˆé•·ç‡: {fundamental_data.get('growth', {}).get('revenue_growth', 'N/A')}
- å–¶æ¥­åˆ©ç›Šç‡: {fundamental_data.get('profitability', {}).get('operating_margin', 'N/A')}
- è‡ªå·±è³‡æœ¬æ¯”ç‡: {fundamental_data.get('financial_health', {}).get('current_ratio', 'N/A')}
"""
            summary_parts.append(fund_summary)

        # ãƒã‚¯ãƒ­ãƒ‡ãƒ¼ã‚¿
        if macro_data:
            macro_summary = f"""
ã€ãƒã‚¯ãƒ­ç’°å¢ƒã€‘
- å¸‚å ´ãƒ¬ã‚¸ãƒ¼ãƒ : {macro_data.get('market_regime', {}).get('regime', 'N/A')}
- ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«: {macro_data.get('market_regime', {}).get('risk_level', 'N/A')}
- æ¨å¥¨ã‚»ã‚¯ã‚¿ãƒ¼: {', '.join(macro_data.get('sector_rotation', {}).get('recommended_sectors', [])[:3])}
"""
            if 'forex' in macro_data:
                forex = macro_data['forex']
                macro_summary += f"- ãƒ‰ãƒ«å††: {forex.get('usdjpy', {}).get('rate', 'N/A')}\n"
            summary_parts.append(macro_summary)

        # ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿
        if news_data:
            news_summary = f"""
ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ»ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆã€‘
- ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆã‚¹ã‚³ã‚¢: {news_data.get('sentiment_score', 50)}/100
- ç·åˆã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆ: {news_data.get('overall_sentiment', 'ä¸­ç«‹')}
- ãƒã‚¸ãƒ†ã‚£ãƒ–ãƒ‹ãƒ¥ãƒ¼ã‚¹: {news_data.get('positive_count', 0)}ä»¶
- ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ‹ãƒ¥ãƒ¼ã‚¹: {news_data.get('negative_count', 0)}ä»¶
"""
            if 'positive_headlines' in news_data:
                for headline in news_data['positive_headlines'][:2]:
                    news_summary += f"- [ãƒã‚¸] {headline.get('title', '')[:50]}\n"
            if 'negative_headlines' in news_data:
                for headline in news_data['negative_headlines'][:2]:
                    news_summary += f"- [ãƒã‚¬] {headline.get('title', '')[:50]}\n"
            summary_parts.append(news_summary)

        # ç‰¹è¨±ãƒ‡ãƒ¼ã‚¿
        if patent_data:
            patent_summary = f"""
ã€ç‰¹è¨±ãƒ»æŠ€è¡“åŠ›ã€‘
- æŠ€è¡“ã‚¹ã‚³ã‚¢: {patent_data.get('tech_score', 'N/A')}/100
- æŠ€è¡“ã‚°ãƒ¬ãƒ¼ãƒ‰: {patent_data.get('tech_grade', 'N/A')}
- ç™ºè¦‹ç‰¹è¨±æ•°: {patent_data.get('total_patents_found', 0)}
- ä¸»è¦æŠ€è¡“åˆ†é‡: {', '.join(list(patent_data.get('technology_areas', {}).keys())[:5])}
"""
            summary_parts.append(patent_summary)

        # ã‚¢ãƒ«ãƒ•ã‚¡ã‚·ã‚°ãƒŠãƒ«
        if alpha_signal:
            alpha_summary = f"""
ã€ã‚¢ãƒ«ãƒ•ã‚¡ã‚·ã‚°ãƒŠãƒ«ã€‘
- ã‚·ã‚°ãƒŠãƒ«: {alpha_signal.get('signal_type', 'N/A')}
- å¼·åº¦: {alpha_signal.get('strength', 0)}/100
- èª¬æ˜: {alpha_signal.get('description', '')}
"""
            summary_parts.append(alpha_summary)

        return "\n".join(summary_parts)

    def generate_quick_analysis(self, ticker: str, company_name: str, info: Dict) -> Generator[str, None, None]:
        """ã‚¯ã‚¤ãƒƒã‚¯åˆ†æã‚’ç”Ÿæˆ"""
        prompt = ChatPromptTemplate.from_template("""
ã‚ãªãŸã¯æ—¥æœ¬æ ªå°‚é–€ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®éŠ˜æŸ„æƒ…å ±ã«åŸºã¥ã„ã¦ã€ç°¡æ½”ãªæŠ•è³‡åˆ†æã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚

éŠ˜æŸ„: {company_name}ï¼ˆ{ticker}ï¼‰
ç¾åœ¨æ ªä¾¡: {current_price}å††
æ™‚ä¾¡ç·é¡: {market_cap}
PER: {per}
PBR: {pbr}
é…å½“åˆ©å›ã‚Š: {dividend_yield}
ROE: {roe}
ã‚»ã‚¯ã‚¿ãƒ¼: {sector}

ã€å‡ºåŠ›å½¢å¼ã€‘
## {company_name} ã‚¯ã‚¤ãƒƒã‚¯åˆ†æ

### æŠ•è³‡åˆ¤æ–­
[è²·ã„/ä¸­ç«‹/å£²ã‚Š] - ç†ç”±ã‚’1æ–‡ã§

### æ³¨ç›®ãƒã‚¤ãƒ³ãƒˆ
- ãƒã‚¤ãƒ³ãƒˆ1
- ãƒã‚¤ãƒ³ãƒˆ2
- ãƒã‚¤ãƒ³ãƒˆ3

### ãƒªã‚¹ã‚¯
- ãƒªã‚¹ã‚¯1
- ãƒªã‚¹ã‚¯2

â€»ç°¡æ½”ã«æ—¥æœ¬èªã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
""")

        chain = prompt | self.llm | StrOutputParser()

        for chunk in chain.stream({
            "ticker": ticker,
            "company_name": company_name,
            "current_price": info.get("current_price", "N/A"),
            "market_cap": info.get("market_cap", "N/A"),
            "per": info.get("pe_ratio", "N/A"),
            "pbr": info.get("pb_ratio", "N/A"),
            "dividend_yield": info.get("dividend_yield", "N/A"),
            "roe": info.get("roe", "N/A"),
            "sector": info.get("sector", "N/A")
        }):
            yield chunk

    def research_topic(self, topic: str, status_container=None) -> Dict:
        """ãƒˆãƒ”ãƒƒã‚¯ã«é–¢ã™ã‚‹è‡ªå¾‹ãƒªã‚µãƒ¼ãƒã‚’å®Ÿè¡Œ"""
        all_notes = ""
        visited_urls = set()

        if status_container:
            status_container.write("ğŸ¤” èª¿æŸ»è¨ˆç”»ã‚’ç«‹æ¡ˆä¸­...")

        queries = self._plan_research(topic)

        if status_container:
            status_container.write(f"ğŸ“‹ æ¤œç´¢ãƒ—ãƒ©ãƒ³: {queries}")

        if status_container:
            status_container.write("ğŸŒ Webèª¿æŸ»ã‚’é–‹å§‹...")

        for q in queries:
            if status_container:
                status_container.write(f"ğŸ” æ¤œç´¢ä¸­: {q}...")

            results = self.search_web(q, max_results=3)

            for res in results:
                url = res.get('href', '')
                if url in visited_urls:
                    continue
                visited_urls.add(url)

                if status_container:
                    status_container.write(f"ğŸ“– èª­è§£ä¸­: {res.get('title', '')}...")

                content = self.fetch_content(url)
                if content:
                    summary = self._summarize_content(topic, content[:5000])
                    all_notes += f"\n--- Source: {res.get('title', '')} ({url}) ---\n{summary}\n"

        return {
            "topic": topic,
            "notes": all_notes,
            "sources_count": len(visited_urls)
        }

    def _plan_research(self, topic: str) -> List[str]:
        """ãƒªã‚µãƒ¼ãƒã‚¯ã‚¨ãƒªã‚’è¨ˆç”»"""
        prompt = ChatPromptTemplate.from_template("""
ã‚ãªãŸã¯æŠ•è³‡ãƒªã‚µãƒ¼ãƒãƒ£ãƒ¼ã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä¾é ¼ï¼šã€Œ{topic}ã€

ã“ã®ä¾é ¼ã‚’é”æˆã™ã‚‹ãŸã‚ã«å¿…è¦ãªæƒ…å ±ã‚’é›†ã‚ã‚‹ãŸã‚ã®ã€ŒWebæ¤œç´¢ã‚¯ã‚¨ãƒªã€ã‚’3ã¤è€ƒãˆã¦ãã ã•ã„ã€‚

å‡ºåŠ›å½¢å¼:
- ã‚¯ã‚¨ãƒª1
- ã‚¯ã‚¨ãƒª2
- ã‚¯ã‚¨ãƒª3
(ä½™è¨ˆãªèª¬æ˜ã¯ä¸è¦ã€‚ã‚¯ã‚¨ãƒªã®ã¿ã‚’ç®‡æ¡æ›¸ãã§å‡ºåŠ›)
""")
        chain = prompt | self.llm | StrOutputParser()
        response = chain.invoke({"topic": topic})
        queries = [line.strip("- ").strip() for line in response.split("\n") if line.strip()]
        return queries[:3]

    def _summarize_content(self, topic: str, content: str) -> str:
        """ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’è¦ç´„"""
        prompt = ChatPromptTemplate.from_template("""
ãƒ†ãƒ¼ãƒï¼šã€Œ{topic}ã€

ä»¥ä¸‹ã®å†…å®¹ã‹ã‚‰ã€ãƒ†ãƒ¼ãƒã«é–¢é€£ã™ã‚‹é‡è¦ãªäº‹å®Ÿã€æ•°å€¤ã€æ„è¦‹ã‚’æŠ½å‡ºã—ã¦ã€æ—¥æœ¬èªã®çŸ­ã„ãƒ¡ãƒ¢ã«ã—ã¦ãã ã•ã„ã€‚

å†…å®¹:
{content}
""")
        chain = prompt | self.llm | StrOutputParser()
        return chain.invoke({"topic": topic, "content": content[:5000]})

    def generate_sector_report(self, sector: str, stocks: List[Dict]) -> Generator[str, None, None]:
        """ã‚»ã‚¯ã‚¿ãƒ¼åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        stocks_info = "\n".join([
            f"- {s.get('ticker')}: {s.get('name', '')} (PER: {s.get('per', 'N/A')}, ROE: {s.get('roe', 'N/A')})"
            for s in stocks[:10]
        ])

        prompt = ChatPromptTemplate.from_template("""
ã‚ãªãŸã¯ã‚»ã‚¯ã‚¿ãƒ¼ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®ã‚»ã‚¯ã‚¿ãƒ¼ã¨éŠ˜æŸ„æƒ…å ±ã«åŸºã¥ã„ã¦ã€ã‚»ã‚¯ã‚¿ãƒ¼åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ã‚»ã‚¯ã‚¿ãƒ¼: {sector}

ä¸»è¦éŠ˜æŸ„:
{stocks_info}

ã€ãƒ¬ãƒãƒ¼ãƒˆå½¢å¼ã€‘
# {sector}ã‚»ã‚¯ã‚¿ãƒ¼åˆ†æ

## ã‚»ã‚¯ã‚¿ãƒ¼æ¦‚æ³
ï¼ˆç¾åœ¨ã®å¸‚å ´ç’°å¢ƒã¨æ¥­ç•Œå‹•å‘ï¼‰

## æ³¨ç›®éŠ˜æŸ„
ï¼ˆæŠ•è³‡å¦™å‘³ã®ã‚ã‚‹éŠ˜æŸ„ã¨ãã®ç†ç”±ï¼‰

## ã‚»ã‚¯ã‚¿ãƒ¼è¦‹é€šã—
ï¼ˆä»Šå¾Œã®å±•æœ›ã¨ã‚«ã‚¿ãƒªã‚¹ãƒˆï¼‰

## æŠ•è³‡æˆ¦ç•¥
ï¼ˆã‚»ã‚¯ã‚¿ãƒ¼ã¸ã®æŠ•è³‡ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼‰

æ—¥æœ¬èªã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
""")

        chain = prompt | self.llm | StrOutputParser()

        for chunk in chain.stream({
            "sector": sector,
            "stocks_info": stocks_info
        }):
            yield chunk

    def compare_stocks(self, stocks_data: List[Dict]) -> Generator[str, None, None]:
        """è¤‡æ•°éŠ˜æŸ„ã®æ¯”è¼ƒåˆ†æ"""
        comparison_table = "| éŠ˜æŸ„ | PER | PBR | ROE | é…å½“åˆ©å›ã‚Š |\n|---|---|---|---|---|\n"
        for s in stocks_data:
            comparison_table += f"| {s.get('ticker', '')} | {s.get('per', 'N/A')} | {s.get('pbr', 'N/A')} | {s.get('roe', 'N/A')} | {s.get('dividend_yield', 'N/A')} |\n"

        prompt = ChatPromptTemplate.from_template("""
ã‚ãªãŸã¯æ ªå¼ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®éŠ˜æŸ„ã‚’æ¯”è¼ƒåˆ†æã—ã¦ãã ã•ã„ã€‚

{comparison_table}

ã€å‡ºåŠ›å½¢å¼ã€‘
## éŠ˜æŸ„æ¯”è¼ƒåˆ†æ

### ãƒãƒªãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³æ¯”è¼ƒ
ï¼ˆå„éŠ˜æŸ„ã®å‰²å®‰åº¦ã‚’æ¯”è¼ƒï¼‰

### åç›Šæ€§æ¯”è¼ƒ
ï¼ˆROEç­‰ã®åç›Šæ€§æŒ‡æ¨™ã‚’æ¯”è¼ƒï¼‰

### æŠ•è³‡æ¨å¥¨
ï¼ˆæœ€ã‚‚é­…åŠ›çš„ãªéŠ˜æŸ„ã¨ãã®ç†ç”±ï¼‰

æ—¥æœ¬èªã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
""")

        chain = prompt | self.llm | StrOutputParser()

        for chunk in chain.stream({"comparison_table": comparison_table}):
            yield chunk

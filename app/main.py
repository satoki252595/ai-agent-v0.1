# -*- coding: utf-8 -*-
"""
æ—¥æœ¬æ ªãƒªã‚µãƒ¼ãƒAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
Japan Stock Research AI Agent

ã‚·ãƒ³ãƒ—ãƒ«ãªãƒãƒ£ãƒƒãƒˆå½¢å¼ã®AIãƒªã‚µãƒ¼ãƒã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ
ãƒ­ãƒ¼ã‚«ãƒ«DBï¼ˆTinyDB + ChromaDBï¼‰ã¨é€£æº
"""
import streamlit as st
import sys
import os
import re
from datetime import datetime

# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from modules.stock_data import StockDataFetcher
from modules.technical import TechnicalAnalyzer
from modules.fundamental import FundamentalAnalyzer
from modules.macro import MacroAnalyzer
from modules.patent import PatentResearcher
from modules.alpha import AlphaFinder
from modules.news import NewsAnalyzer
from modules.ai_agent import StockResearchAgent

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
from database.stock_db import StockDatabase
from database.vector_db import VectorDatabase

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(
    page_title="æ—¥æœ¬æ ªAI",
    page_icon="ğŸ¤–",
    layout="centered",
    initial_sidebar_state="collapsed"
)

# --- ã‚·ãƒ³ãƒ—ãƒ«CSS ---
st.markdown("""
<style>
    :root {
        --primary: #6366f1;
        --bg-dark: #0f0f0f;
        --bg-card: #1a1a1a;
        --bg-input: #252525;
        --text-primary: #ffffff;
        --text-secondary: #a1a1aa;
        --border: #2a2a2a;
    }

    .stApp {
        background: var(--bg-dark) !important;
        color: var(--text-primary) !important;
    }

    [data-testid="stSidebar"] { display: none; }
    [data-testid="stHeader"] { background: transparent !important; }
    footer { display: none !important; }

    .main .block-container {
        padding: 1rem !important;
        max-width: 800px !important;
    }

    .app-title {
        text-align: center;
        font-size: 1.5rem;
        font-weight: 700;
        padding: 1rem 0;
        color: var(--primary);
    }

    .message {
        padding: 1rem;
        border-radius: 0.75rem;
        margin-bottom: 0.75rem;
    }

    .message-user {
        background: var(--primary);
        color: white;
    }

    .message-ai {
        background: var(--bg-card);
        border: 1px solid var(--border);
    }

    .stTextArea textarea {
        background: var(--bg-input) !important;
        border: 1px solid var(--border) !important;
        border-radius: 0.5rem !important;
        color: var(--text-primary) !important;
    }

    .stButton > button {
        background: var(--primary) !important;
        color: white !important;
        border: none !important;
        border-radius: 0.5rem !important;
    }
</style>
""", unsafe_allow_html=True)


# --- ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ– ---
if "messages" not in st.session_state:
    st.session_state.messages = []
if "processing" not in st.session_state:
    st.session_state.processing = False

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼‰
@st.cache_resource
def get_stock_db():
    """æ§‹é€ åŒ–DBã‚’å–å¾—"""
    return StockDatabase()

@st.cache_resource
def get_vector_db():
    """ãƒ™ã‚¯ãƒˆãƒ«DBã‚’å–å¾—"""
    return VectorDatabase()

stock_db = get_stock_db()
vector_db = get_vector_db()


# --- ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° ---
def extract_ticker(text: str) -> str:
    """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ã‚’æŠ½å‡º"""
    # 4æ¡ã®æ•°å­—ãƒ‘ã‚¿ãƒ¼ãƒ³
    match = re.search(r'\b(\d{4})\b', text)
    if match:
        return match.group(1)
    return None


def analyze_stock(ticker: str) -> dict:
    """
    éŠ˜æŸ„ã‚’åˆ†æã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    DBã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒã‚ã‚Œã°å„ªå…ˆçš„ã«ä½¿ç”¨ã€ãªã‘ã‚Œã°ãƒ©ã‚¤ãƒ–ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦DBã«ä¿å­˜
    """
    result = {
        "info": None,
        "technical": None,
        "fundamental": None,
        "from_cache": False
    }

    # 1. DBã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèª
    if stock_db.is_data_fresh(ticker, "stocks", max_age_hours=6):
        cached_info = stock_db.get_stock(ticker)
        if cached_info:
            result["info"] = cached_info
            result["from_cache"] = True

            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºã‚‚å–å¾—
            cached_fund = stock_db.get_fundamentals(ticker)
            if cached_fund:
                result["fundamental"] = cached_fund

            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ã‚‚å–å¾—
            cached_tech = stock_db.get_technicals(ticker)
            if cached_tech:
                result["technical"] = cached_tech

    # 2. ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒãªã„å ´åˆã¯ãƒ©ã‚¤ãƒ–ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    if not result["info"]:
        fetcher = StockDataFetcher()
        info = fetcher.get_stock_info(ticker)

        if "error" in info:
            return None

        result["info"] = info

        # DBã«ä¿å­˜
        stock_db.upsert_stock(ticker, info)

        # ä¾¡æ ¼å±¥æ­´ã‚’å–å¾—ãƒ»ä¿å­˜
        hist = fetcher.get_historical_data(ticker, "3mo")
        if not hist.empty:
            prices = []
            for date, row in hist.iterrows():
                prices.append({
                    "date": date.strftime("%Y-%m-%d"),
                    "open": float(row["open"]) if "open" in row else 0,
                    "high": float(row["high"]) if "high" in row else 0,
                    "low": float(row["low"]) if "low" in row else 0,
                    "close": float(row["close"]) if "close" in row else 0,
                    "volume": int(row["volume"]) if "volume" in row else 0
                })
            stock_db.save_prices(ticker, prices)

            # ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«åˆ†æ
            ta = TechnicalAnalyzer(hist)
            tech_data = ta.get_trend_summary()
            result["technical"] = tech_data
            stock_db.save_technicals(ticker, tech_data)

        # ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«åˆ†æ
        fa = FundamentalAnalyzer(ticker)
        fund_data = fa.get_analysis_summary()
        result["fundamental"] = fund_data
        stock_db.save_fundamentals(ticker, fund_data)

        # ãƒ™ã‚¯ãƒˆãƒ«DBã«ä¼æ¥­æƒ…å ±ã‚’ä¿å­˜
        if info.get("description"):
            vector_db.add_company_description(
                ticker=ticker,
                name=info.get("name", ""),
                description=info.get("description", ""),
                sector=info.get("sector", ""),
                industry=info.get("industry", "")
            )

    return result


def get_macro_context() -> dict:
    """ãƒã‚¯ãƒ­çµŒæ¸ˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—"""
    macro = MacroAnalyzer()
    return {
        "indices": macro.get_global_indices(),
        "forex": macro.get_forex_rates(),
        "regime": macro.get_market_regime()
    }


def search_related_info(query: str, ticker: str = None) -> dict:
    """
    ãƒ™ã‚¯ãƒˆãƒ«DBã‹ã‚‰é–¢é€£æƒ…å ±ã‚’ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢
    """
    results = {}

    # é¡ä¼¼ä¼æ¥­ã‚’æ¤œç´¢
    similar_companies = vector_db.search_companies(query, n_results=3)
    if similar_companies:
        results["similar_companies"] = similar_companies

    # é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’æ¤œç´¢
    if ticker:
        news = vector_db.search_news(query, ticker=ticker, n_results=5)
    else:
        news = vector_db.search_news(query, n_results=5)
    if news:
        results["related_news"] = news

    # ãƒªã‚µãƒ¼ãƒãƒãƒ¼ãƒˆã‚’æ¤œç´¢
    research = vector_db.search_research(query, ticker=ticker, n_results=3)
    if research:
        results["research_notes"] = research

    return results


def get_realtime_news(ticker: str, company_name: str) -> dict:
    """
    ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§æ ªå¼ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—ãƒ»åˆ†æ

    Args:
        ticker: éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰
        company_name: ä¼æ¥­å

    Returns:
        ãƒ‹ãƒ¥ãƒ¼ã‚¹åˆ†æçµæœ
    """
    news_analyzer = NewsAnalyzer()
    return news_analyzer.get_realtime_stock_news(ticker, company_name)


# --- ãƒ¡ã‚¤ãƒ³UI ---
# ã‚µãƒ¼ãƒ“ã‚¹å
st.markdown('<div class="app-title">æ—¥æœ¬æ ªãƒªã‚µãƒ¼ãƒAI</div>', unsafe_allow_html=True)

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
for msg in st.session_state.messages:
    if msg["role"] == "user":
        st.markdown(f'<div class="message message-user">{msg["content"]}</div>', unsafe_allow_html=True)
    else:
        st.markdown(f'<div class="message message-ai">{msg["content"]}</div>', unsafe_allow_html=True)

# å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
col1, col2 = st.columns([5, 1])
with col1:
    user_input = st.text_area(
        "è³ªå•",
        placeholder="è³ªå•ã‚’å…¥åŠ›...",
        height=68,
        label_visibility="collapsed",
        key="user_input"
    )
with col2:
    send_button = st.button("é€ä¿¡", type="primary", use_container_width=True)


# é€ä¿¡å‡¦ç†
if send_button and user_input and not st.session_state.processing:
    st.session_state.processing = True
    st.session_state.messages.append({"role": "user", "content": user_input})

    with st.spinner("åˆ†æä¸­..."):
        try:
            agent = StockResearchAgent()

            # éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ã®æŠ½å‡º
            ticker = extract_ticker(user_input)

            # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®æ§‹ç¯‰
            context_data = ""

            if ticker:
                stock_data = analyze_stock(ticker)
                if stock_data:
                    info = stock_data["info"]
                    company_name = info.get('name', '')

                    context_data += f"""
ã€éŠ˜æŸ„æƒ…å ±ã€‘
éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰: {ticker}
ä¼æ¥­å: {company_name}
ç¾åœ¨æ ªä¾¡: Â¥{info.get('current_price', 0):,.0f}
æ™‚ä¾¡ç·é¡: Â¥{info.get('market_cap', 0):,.0f}
PER: {info.get('pe_ratio', 'N/A')}
PBR: {info.get('pb_ratio', 'N/A')}
é…å½“åˆ©å›ã‚Š: {info.get('dividend_yield', 0) * 100 if info.get('dividend_yield') else 0:.2f}%
ROE: {info.get('roe', 0) * 100 if info.get('roe') else 0:.1f}%
ã‚»ã‚¯ã‚¿ãƒ¼: {info.get('sector', 'N/A')}
"""
                    if stock_data["technical"]:
                        tech = stock_data["technical"]
                        context_data += f"""
ã€ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«åˆ†æã€‘
ç·åˆã‚·ã‚°ãƒŠãƒ«: {tech.get('overall_signal', 'N/A')}
ã‚¹ã‚³ã‚¢: {tech.get('score', 0)}
è²·ã„ã‚·ã‚°ãƒŠãƒ«æ•°: {tech.get('buy_signals', 0)}
å£²ã‚Šã‚·ã‚°ãƒŠãƒ«æ•°: {tech.get('sell_signals', 0)}
"""
                    if stock_data["fundamental"]:
                        fund = stock_data["fundamental"]
                        context_data += f"""
ã€ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«åˆ†æã€‘
ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚¹ã‚³ã‚¢: {fund.get('fundamental_score', 0)}/100
ã‚°ãƒ¬ãƒ¼ãƒ‰: {fund.get('fundamental_grade', 'N/A')}
"""
                    # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‹ãƒ¥ãƒ¼ã‚¹æ¤œç´¢
                    news_data = get_realtime_news(ticker, company_name)
                    if news_data:
                        context_data += f"""
ã€æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ»IRæƒ…å ±ã€‘
ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆã‚¹ã‚³ã‚¢: {news_data.get('sentiment_score', 50)}/100
ç·åˆã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆ: {news_data.get('overall_sentiment', 'ä¸­ç«‹')}
ãƒã‚¸ãƒ†ã‚£ãƒ–ãƒ‹ãƒ¥ãƒ¼ã‚¹: {news_data.get('positive_count', 0)}ä»¶
ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ‹ãƒ¥ãƒ¼ã‚¹: {news_data.get('negative_count', 0)}ä»¶
ã‚µãƒãƒªãƒ¼: {news_data.get('news_summary', '')}
"""
                        # IRãƒ‹ãƒ¥ãƒ¼ã‚¹
                        ir_news = news_data.get('ir_news', [])
                        if ir_news:
                            context_data += "\nã€IRé–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ã€‘\n"
                            for article in ir_news[:3]:
                                sentiment_mark = "ğŸ“ˆ" if article.get('sentiment') == "ãƒã‚¸ãƒ†ã‚£ãƒ–" else "ğŸ“‰" if article.get('sentiment') == "ãƒã‚¬ãƒ†ã‚£ãƒ–" else "â–"
                                context_data += f"- {sentiment_mark} {article.get('title', '')[:60]}... ({article.get('source', '')})\n"

                        # ä¸€èˆ¬ãƒ‹ãƒ¥ãƒ¼ã‚¹
                        general_news = news_data.get('general_news', [])
                        if general_news:
                            context_data += "\nã€ä¸€èˆ¬ãƒ‹ãƒ¥ãƒ¼ã‚¹ã€‘\n"
                            for article in general_news[:3]:
                                sentiment_mark = "ğŸ“ˆ" if article.get('sentiment') == "ãƒã‚¸ãƒ†ã‚£ãƒ–" else "ğŸ“‰" if article.get('sentiment') == "ãƒã‚¬ãƒ†ã‚£ãƒ–" else "â–"
                                context_data += f"- {sentiment_mark} {article.get('title', '')[:60]}... ({article.get('source', '')})\n"

            # ãƒã‚¯ãƒ­æƒ…å ±ãŒå¿…è¦ãã†ãªå ´åˆ
            if any(word in user_input for word in ["å¸‚å ´", "ç’°å¢ƒ", "ãƒã‚¯ãƒ­", "æ—¥çµŒ", "ç›¸å ´", "ã‚»ã‚¯ã‚¿ãƒ¼"]):
                macro_data = get_macro_context()
                regime = macro_data.get("regime", {})
                context_data += f"""
ã€å¸‚å ´ç’°å¢ƒã€‘
å¸‚å ´ãƒ¬ã‚¸ãƒ¼ãƒ : {regime.get('regime', 'N/A')}
ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«: {regime.get('risk_level', 'N/A')}
"""
                if macro_data.get("indices", {}).get("nikkei225"):
                    nk = macro_data["indices"]["nikkei225"]
                    context_data += f"æ—¥çµŒå¹³å‡: Â¥{nk.get('value', 0):,.0f} ({nk.get('change_pct', 0):.2f}%)\n"
                if macro_data.get("forex", {}).get("usdjpy"):
                    fx = macro_data["forex"]["usdjpy"]
                    context_data += f"USD/JPY: Â¥{fx.get('rate', 0):.2f}\n"

                # å¸‚å ´ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—
                news_analyzer = NewsAnalyzer()
                market_sentiment = news_analyzer.get_market_sentiment()
                if market_sentiment:
                    context_data += f"""
ã€å¸‚å ´ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆã€‘
å¸‚å ´ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆã‚¹ã‚³ã‚¢: {market_sentiment.get('market_sentiment_score', 50)}/100
å¸‚å ´ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆ: {market_sentiment.get('market_sentiment', 'ä¸­ç«‹')}
ã‚µãƒãƒªãƒ¼: {market_sentiment.get('summary', '')}
"""
                    top_news = market_sentiment.get('top_news', [])
                    if top_news:
                        context_data += "\nã€æœ¬æ—¥ã®ä¸»è¦ãƒ‹ãƒ¥ãƒ¼ã‚¹ã€‘\n"
                        for article in top_news[:4]:
                            sentiment_mark = "ğŸ“ˆ" if article.get('sentiment') == "ãƒã‚¸ãƒ†ã‚£ãƒ–" else "ğŸ“‰" if article.get('sentiment') == "ãƒã‚¬ãƒ†ã‚£ãƒ–" else "â–"
                            context_data += f"- {sentiment_mark} {article.get('title', '')[:50]}... ({article.get('source', '')})\n"

            # ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ãŒå¿…è¦ãã†ãªå ´åˆ
            if any(word in user_input for word in ["æ¢ã—ã¦", "ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°", "å‰²å®‰", "é«˜é…å½“", "æˆé•·", "ãŠã™ã™ã‚"]):
                alpha = AlphaFinder()
                if "å‰²å®‰" in user_input or "ãƒãƒªãƒ¥ãƒ¼" in user_input:
                    df = alpha.screen_value_stocks()
                    if not df.empty:
                        top_5 = df.head(5)
                        context_data += "\nã€ãƒãƒªãƒ¥ãƒ¼æ ªã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°çµæœã€‘\n"
                        for _, row in top_5.iterrows():
                            context_data += f"- {row['ticker']}: PER {row.get('per', 'N/A')}, PBR {row.get('pbr', 'N/A')}\n"

                elif "é«˜é…å½“" in user_input:
                    df = alpha.screen_value_stocks()
                    if not df.empty:
                        top_5 = df.sort_values("dividend_yield", ascending=False).head(5)
                        context_data += "\nã€é«˜é…å½“æ ªã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°çµæœã€‘\n"
                        for _, row in top_5.iterrows():
                            yield_pct = row.get('dividend_yield', 0) * 100 if row.get('dividend_yield') else 0
                            context_data += f"- {row['ticker']}: é…å½“åˆ©å›ã‚Š {yield_pct:.2f}%\n"

                elif "æˆé•·" in user_input or "ã‚°ãƒ­ãƒ¼ã‚¹" in user_input:
                    df = alpha.screen_growth_stocks()
                    if not df.empty:
                        top_5 = df.head(5)
                        context_data += "\nã€ã‚°ãƒ­ãƒ¼ã‚¹æ ªã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°çµæœã€‘\n"
                        for _, row in top_5.iterrows():
                            context_data += f"- {row['ticker']}: å£²ä¸Šæˆé•· {row.get('revenue_growth', 0)*100:.1f}%\n"

            # AIãƒ¬ã‚¹ãƒãƒ³ã‚¹ç”Ÿæˆ
            response_container = st.empty()
            full_response = ""

            from langchain_core.prompts import ChatPromptTemplate
            from langchain_core.output_parsers import StrOutputParser

            prompt = ChatPromptTemplate.from_template("""ã‚ãªãŸã¯æ—¥æœ¬æ ªå°‚é–€ã®AIã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã—ã¦ã€å°‚é–€çš„ã‹ã¤ã‚ã‹ã‚Šã‚„ã™ãå›ç­”ã—ã¦ãã ã•ã„ã€‚

{context}

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {question}

ã€å›ç­”ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã€‘
- ç°¡æ½”ã§èª­ã¿ã‚„ã™ã„å½¢å¼ã§å›ç­”
- é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã¯ç®‡æ¡æ›¸ãã‚’ä½¿ç”¨
- æŠ•è³‡åˆ¤æ–­ã«å½¹ç«‹ã¤å…·ä½“çš„ãªæƒ…å ±ã‚’æä¾›
- ãƒªã‚¹ã‚¯ã«ã¤ã„ã¦ã‚‚è¨€åŠ
- æ—¥æœ¬èªã§å›ç­”

ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ»IRæƒ…å ±ã®æ´»ç”¨ã€‘
- æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚„IRæƒ…å ±ãŒæä¾›ã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ã€å¿…ãšåˆ†æã«åæ˜ 
- ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆï¼ˆãƒã‚¸ãƒ†ã‚£ãƒ–/ãƒã‚¬ãƒ†ã‚£ãƒ–ï¼‰ã‚’è€ƒæ…®ã—ãŸè¦‹é€šã—ã‚’æç¤º
- æ±ºç®—ãƒ»é…å½“ãƒ»M&Aç­‰ã®é‡è¦IRã¯æŠ•è³‡åˆ¤æ–­ã®ææ–™ã¨ã—ã¦è¨€åŠ
- ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ãƒˆãƒ¬ãƒ³ãƒ‰ã‹ã‚‰çŸ­æœŸçš„ãªæ ªä¾¡ã¸ã®å½±éŸ¿ã‚’æ¨æ¸¬

å›ç­”:""")

            chain = prompt | agent.llm | StrOutputParser()

            for chunk in chain.stream({
                "context": context_data if context_data else "ç‰¹å®šã®éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ä¸€èˆ¬çš„ãªçŸ¥è­˜ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚",
                "question": user_input
            }):
                full_response += chunk
                response_container.markdown(f'<div class="message message-ai">{full_response}</div>', unsafe_allow_html=True)

            st.session_state.messages.append({"role": "assistant", "content": full_response})

        except Exception as e:
            error_msg = f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
            st.session_state.messages.append({"role": "assistant", "content": error_msg})

    st.session_state.processing = False
    st.rerun()

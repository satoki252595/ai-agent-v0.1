import streamlit as st
import os
import tempfile
import re
from urllib.parse import urljoin
from langchain_ollama import ChatOllama
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_community.document_loaders import PyPDFLoader

# --- æ–°è¦å°å…¥ãƒ©ã‚¤ãƒ–ãƒ©ãƒª ---
import trafilatura
from tenacity import retry, stop_after_attempt, wait_fixed, retry_if_exception_type

# --- è¨­å®š ---
OLLAMA_URL = st.secrets.get("OLLAMA_BASE_URL", "http://localhost:11435")
MODEL_NAME = st.secrets.get("MODEL_NAME", "nemotron-3-nano")

st.set_page_config(
    page_title="è¦ç´„ãã‚“",
    page_icon="ğŸ“",
    layout="centered",
    initial_sidebar_state="collapsed"
)

# --- UI/UX: ãƒ‡ã‚¶ã‚¤ãƒ³ã®å¼·åˆ¶å›ºå®š (ã©ã®ç«¯æœ«ã§ã‚‚å´©ã‚Œãªã„è¨­å®š) ---
st.markdown("""
<style>
    /* 1. ãƒ™ãƒ¼ã‚¹ã‚«ãƒ©ãƒ¼ã®å¼·åˆ¶ (ç«¯æœ«è¨­å®šã‚’ç„¡è¦–) */
    .stApp {
        background-color: #121212 !important;
        color: #e0e0e0 !important;
        font-family: 'Hiragino Kaku Gothic ProN', 'Meiryo', sans-serif !important;
    }

    /* 2. å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ã®è¦–èªæ€§ç¢ºä¿ */
    .stTextInput > div > div > input {
        background-color: #1e1e1e !important;
        color: #ffffff !important;
        border: 1px solid #444 !important;
        caret-color: #2563eb !important; /* ã‚«ãƒ¼ã‚½ãƒ«ã®è‰² */
    }
    /* ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã®è‰² */
    ::placeholder {
        color: #888 !important;
        opacity: 1 !important;
    }

    /* 3. ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ‡ã‚¶ã‚¤ãƒ³ (æ¨ªã‚¹ã‚¯ãƒ­ãƒ¼ãƒ« & é…è‰²å›ºå®š) */
    [data-testid="stMarkdownContainer"] table {
        display: block;
        overflow-x: auto;
        white-space: nowrap;
        border-collapse: collapse;
        width: 100%;
        margin: 20px 0;
        border: 1px solid #333;
    }
    [data-testid="stMarkdownContainer"] th {
        background-color: #2d2d2d !important;
        color: #ffffff !important;
        border-bottom: 2px solid #555 !important;
        padding: 12px;
    }
    [data-testid="stMarkdownContainer"] td {
        background-color: #1a1a1a !important;
        color: #ddd !important;
        border-bottom: 1px solid #333 !important;
        padding: 10px;
    }
    [data-testid="stMarkdownContainer"] tr:nth-child(even) td {
        background-color: #252525 !important; /* ã‚¹ãƒˆãƒ©ã‚¤ãƒ— */
    }

    /* 4. ãã®ä»–UIãƒ‘ãƒ¼ãƒ„ */
    h1, h2, h3, p, li, label, .stMarkdown {
        color: #e0e0e0 !important;
    }
    h1 {
        background: -webkit-linear-gradient(45deg, #eee, #aaa);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent !important;
    }
    
    /* ãƒœã‚¿ãƒ³ */
    .stButton > button {
        background: linear-gradient(90deg, #2563eb, #3b82f6) !important;
        color: white !important;
        border: none !important;
        font-weight: bold !important;
        transition: opacity 0.2s;
    }
    .stButton > button:active {
        opacity: 0.8;
    }

    /* ãƒªãƒ³ã‚¯è‰² */
    a { color: #4da6ff !important; }

    /* ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒãƒ¼ */
    .stStatusWidget {
        background-color: #1e1e1e !important;
        border: 1px solid #333 !important;
        color: #e0e0e0 !important;
    }
</style>
""", unsafe_allow_html=True)

# --- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ ---
PROMPT_TEMPLATES = {
    "ãƒ“ã‚¸ãƒã‚¹ãƒ»æˆ¦ç•¥ (çµŒå–¶å±¤å‘ã‘)": """
ã‚ãªãŸã¯æˆ¦ç•¥ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆAIã§ã™ã€‚
å…¥åŠ›æƒ…å ±ã‚’åˆ†æã—ã€æ„æ€æ±ºå®šã®ãŸã‚ã®ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ã€å‡ºåŠ›è¦ä»¶ã€‘
1. **æ¯”è¼ƒã‚„æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã¯Markdownã®è¡¨ï¼ˆTableï¼‰ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚**
2. çµè«–ã‹ã‚‰è¿°ã¹ã‚‹ï¼ˆã‚¢ãƒ³ã‚µãƒ¼ãƒ•ã‚¡ãƒ¼ã‚¹ãƒˆï¼‰ã€‚
3. å‚ç…§ãƒªãƒ³ã‚¯ã®æƒ…å ±ã¯ã€ãƒ¡ã‚¤ãƒ³è¨˜äº‹ã®è£œå¼·ã«å¿…è¦ãªå ´åˆã®ã¿çµ±åˆã—ã¦ãã ã•ã„ã€‚

ã€æ§‹é€ ã€‘
# ã‚¿ã‚¤ãƒˆãƒ«
## ğŸ¯ ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼
## ğŸ“Š é‡è¦æŒ‡æ¨™ (è¡¨ã§å¯è¦–åŒ–)
## ğŸš€ ãƒ“ã‚¸ãƒã‚¹ã¸ã®å½±éŸ¿ã¨ç¤ºå”†
    """,
    "ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒ»æŠ€è¡“ (é–‹ç™ºè€…å‘ã‘)": """
ã‚ãªãŸã¯ã‚·ãƒ‹ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã§ã™ã€‚
æŠ€è¡“è©³ç´°ã€ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚

ã€å‡ºåŠ›è¦ä»¶ã€‘
1. **æŠ€è¡“æ¯”è¼ƒã€ãƒ¡ãƒªãƒƒãƒˆãƒ»ãƒ‡ãƒ¡ãƒªãƒƒãƒˆã¯Markdownã®è¡¨ï¼ˆTableï¼‰ã§æ•´ç†ã—ã¦ãã ã•ã„ã€‚**
2. ãƒªãƒ³ã‚¯å…ˆã®è©³ç´°æƒ…å ±ã‚‚å«ã‚ã€æŠ€è¡“çš„ãªæ·±æ˜ã‚Šã‚’è¡Œã£ã¦ãã ã•ã„ã€‚

ã€æ§‹é€ ã€‘
# ã‚¿ã‚¤ãƒˆãƒ«
## ğŸ— ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¨è¨­è¨ˆæ€æƒ³
## âš”ï¸ æŠ€è¡“æ¯”è¼ƒãƒ»ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ• (è¡¨ã§å¯è¦–åŒ–)
## ğŸ’¡ å®Ÿè£…ã®ãƒã‚¤ãƒ³ãƒˆ
    """,
    "ã‚¢ã‚«ãƒ‡ãƒŸãƒƒã‚¯ (ç ”ç©¶è€…å‘ã‘)": """
ã‚ãªãŸã¯ãƒˆãƒƒãƒ—ã‚¸ãƒ£ãƒ¼ãƒŠãƒ«ã®æŸ»èª­è€…ã§ã™ã€‚
æ–°è¦æ€§ã€æ‰‹æ³•ã€çµæœã®å¦¥å½“æ€§ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚

ã€å‡ºåŠ›è¦ä»¶ã€‘
1. **å®Ÿé¨“çµæœã®æ¯”è¼ƒã¯Markdownã®è¡¨ï¼ˆTableï¼‰ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚**
2. å®¢è¦³çš„ã§å³å¯†ãªè¡¨ç¾ã‚’ç”¨ã„ã‚‹ã“ã¨ã€‚

ã€æ§‹é€ ã€‘
# ã‚¿ã‚¤ãƒˆãƒ«
## ğŸ”¬ ã‚¢ãƒ–ã‚¹ãƒˆãƒ©ã‚¯ãƒˆ (æ¦‚è¦)
## ğŸ§ª ææ¡ˆæ‰‹æ³•ãƒ»ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
## ğŸ“ˆ çµæœã¨è€ƒå¯Ÿ (è¡¨ã§å¯è¦–åŒ–)
    """,
    "è©³ç´°è§£èª¬ (Deep Dive)": """
ã‚ãªãŸã¯å„ªç§€ãªãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚
è©³ç´°ã‚’çœã‹ãšã«ã€ã‹ã¤åˆ†ã‹ã‚Šã‚„ã™ãè§£èª¬ã—ã¦ãã ã•ã„ã€‚

ã€å‡ºåŠ›è¦ä»¶ã€‘
1. **è¤‡é›‘ãªæƒ…å ±ã¯Markdownã®è¡¨ï¼ˆTableï¼‰ã‚’ä½¿ã£ã¦æ•´ç†ã—ã¦ãã ã•ã„ã€‚**
2. å°‚é–€ç”¨èªã¯å™›ã¿ç •ã„ã¦èª¬æ˜ã™ã‚‹ã€‚
    """
}

# --- ãƒ­ã‚¸ãƒƒã‚¯é–¢æ•° (Trafilatura & Tenacityæ¡ç”¨) ---

def clean_text(text):
    """é€šä¿¡ã‚¨ãƒ©ãƒ¼ã®åŸå› ã¨ãªã‚‹ãƒŒãƒ«æ–‡å­—ç­‰ã‚’å‰Šé™¤"""
    if not text:
        return ""
    text = text.replace('\x00', '')
    text = re.sub(r'[\x00-\x08\x0b\x0c\x0e-\x1f\x7f]', '', text)
    return text

def escape_brackets(text):
    """LangChainç”¨ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—"""
    return text.replace("{", "{{").replace("}", "}}")

# ã€æ”¹å–„ç‚¹ã€‘Tenacityã«ã‚ˆã‚‹è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤ (SSLã‚¨ãƒ©ãƒ¼å¯¾ç­–)
# ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚ã€2ç§’å¾…ã£ã¦æœ€å¤§3å›ã¾ã§å†è©¦è¡Œã™ã‚‹
@retry(stop=stop_after_attempt(3), wait=wait_fixed(2), retry=retry_if_exception_type(Exception))
def fetch_url_content_robust(url):
    """Trafilaturaã‚’ä½¿ç”¨ã—ãŸå …ç‰¢ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„å–å¾—"""
    try:
        # PDFåˆ¤å®š (æ‹¡å¼µå­ã¾ãŸã¯Headãƒªã‚¯ã‚¨ã‚¹ãƒˆ)
        if url.lower().endswith('.pdf'):
            downloaded = trafilatura.downloads.fetch_url(url)
            if downloaded:
                return get_pdf_text_from_bytes(downloaded), "PDF", []
            
        # 1. Trafilaturaã§HTMLå–å¾— (Requestsã‚ˆã‚Šé«˜é€Ÿãƒ»è»½é‡)
        downloaded = trafilatura.downloads.fetch_url(url)
        
        if downloaded is None:
            return "", "å–å¾—å¤±æ•—", []

        # 2. æœ¬æ–‡æŠ½å‡º (BeautifulSoupã‚ˆã‚Šé«˜ç²¾åº¦ã§ãƒã‚¤ã‚ºãŒå°‘ãªã„)
        text = trafilatura.extract(
            downloaded,
            include_comments=False,
            include_tables=True,
            no_fallback=False
        )
        
        if not text:
            # Trafilaturaã§ãƒ€ãƒ¡ãªã‚‰PDFã‹ã‚‚ã—ã‚Œãªã„ã®ã§å¿µã®ç‚ºãƒã‚§ãƒƒã‚¯
            if b"%PDF" in downloaded[:10]:
                 return get_pdf_text_from_bytes(downloaded), "PDF", []
            return "", "æœ¬æ–‡ãªã—", []

        # ã‚¿ã‚¤ãƒˆãƒ«æŠ½å‡º (ç°¡æ˜“çš„)
        match = re.search(r'<title>(.*?)</title>', str(downloaded), re.IGNORECASE)
        title = match.group(1) if match else "ã‚¿ã‚¤ãƒˆãƒ«ãªã—"

        # ãƒªãƒ³ã‚¯æŠ½å‡º (Trafilaturaã¯ãƒªãƒ³ã‚¯æŠ½å‡ºãƒ¡ã‚½ãƒƒãƒ‰ãŒãªã„ãŸã‚ã€ã“ã“ã¯ç°¡æ˜“çš„ã«å‡¦ç†ã™ã‚‹ã‹ã€
        # ã‚ã‚‹ã„ã¯æœ¬æ–‡æŠ½å‡ºæ™‚ã«ãƒªãƒ³ã‚¯ã‚’æ®‹ã™è¨­å®šã«ã™ã‚‹ãŒã€ä»Šå›ã¯ã‚·ãƒ³ãƒ—ãƒ«ã«æ­£è¦è¡¨ç¾ã§æŠ½å‡º)
        # â€»Trafilaturaã¯æœ¬æ–‡ã®ã¿ã‚’ç¶ºéº—ã«æŠœãã®ãŒå¾—æ„ãªãŸã‚ã€ãƒªãƒ³ã‚¯æŠ½å‡ºã¯è£œåŠ©çš„ã«è¡Œã†
        links = []
        # ç°¡æ˜“çš„ãªãƒªãƒ³ã‚¯æŠ½å‡º (httpã‹ã‚‰å§‹ã¾ã‚‹ã‚‚ã®ã‚’æ¢ã™)
        raw_links = re.findall(r'href=[\'"]?([^\'" >]+)', str(downloaded))
        for link in raw_links:
            full_link = urljoin(url, link)
            if full_link.startswith("http") and full_link != url:
                links.append(full_link)

        return clean_text(text), title, list(set(links))

    except Exception as e:
        # TenacityãŒã‚­ãƒ£ãƒƒãƒã—ã¦ãƒªãƒˆãƒ©ã‚¤ã•ã›ã‚‹ãŸã‚ã«ä¾‹å¤–ã‚’å†é€å‡º
        raise e

def get_pdf_text_from_bytes(pdf_bytes):
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
            tmp.write(pdf_bytes)
            tmp_path = tmp.name
        loader = PyPDFLoader(tmp_path)
        pages = loader.load()
        os.remove(tmp_path)
        text = "\n".join([p.page_content for p in pages])
        return clean_text(text)
    except:
        return ""

def deep_dive_analysis(url, enable_deep_dive, max_links, status_container):
    status_container.write(f"ãƒ¡ã‚¤ãƒ³è¨˜äº‹ã‚’å–å¾—ä¸­ (Trafilatura): {url}...")
    
    try:
        main_text, title, found_links = fetch_url_content_robust(url)
    except Exception as e:
        return f"ã‚¨ãƒ©ãƒ¼: è¨˜äº‹ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ ({e})", "ã‚¨ãƒ©ãƒ¼"

    if not main_text:
        return "ã‚¨ãƒ©ãƒ¼: æœ¬æ–‡ã‚’æŠ½å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚", "ã‚¨ãƒ©ãƒ¼"

    combined_text = f"=== ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ (ã‚½ãƒ¼ã‚¹: {url}) ===\n{main_text[:15000]}\n\n"
    
    if enable_deep_dive and found_links:
        # PDFä»¥å¤–ã®ãƒªãƒ³ã‚¯ã«çµã‚‹
        target_links = [l for l in found_links if not l.lower().endswith('.pdf')][:max_links]
        
        if target_links:
            status_container.write(f"ğŸ” æ·±æ˜ã‚Šä¸­: é–¢é€£ãƒªãƒ³ã‚¯ {len(target_links)} ä»¶ã‚’èª¿æŸ»ã—ã¾ã™...")
            
            for i, link in enumerate(target_links):
                try:
                    status_container.write(f"èª­ã¿è¾¼ã¿ä¸­: {link}...")
                    sub_text, _, _ = fetch_url_content_robust(link)
                    if sub_text:
                        combined_text += f"=== å‚è€ƒãƒªãƒ³ã‚¯ {i+1} (ã‚½ãƒ¼ã‚¹: {link}) ===\n{sub_text[:3000]}\n\n"
                except:
                    status_container.write(f"ã‚¹ã‚­ãƒƒãƒ— (å–å¾—å¤±æ•—): {link}")
                    continue
            
    return combined_text, title

# --- ç”»é¢ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ ---

st.title("è¦ç´„ãã‚“")
st.caption("æ–‡è„ˆã‚’ç†è§£ã™ã‚‹AIè¦ç´„ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ v2.0")

with st.expander("âš™ï¸ åˆ†æè¨­å®š (ã‚¯ãƒªãƒƒã‚¯ã—ã¦é–‹ã)", expanded=False):
    selected_persona = st.selectbox("è¦–ç‚¹ (ãƒšãƒ«ã‚½ãƒŠ)", list(PROMPT_TEMPLATES.keys()))
    st.markdown("---")
    enable_deep_dive = st.checkbox("è¨˜äº‹å†…ã®ãƒªãƒ³ã‚¯ã‚‚èª¿æŸ»ã™ã‚‹ (Deep Dive)", value=True)
    max_links = st.slider("èª¿æŸ»ã™ã‚‹ãƒªãƒ³ã‚¯ã®æœ€å¤§æ•°", 1, 5, 2)
    st.markdown("---")
    user_prompt = st.text_area("ã‚«ã‚¹ã‚¿ãƒ æŒ‡ç¤º", value=PROMPT_TEMPLATES[selected_persona], height=150)

tab1, tab2 = st.tabs(["ğŸŒ URLåˆ†æ", "ğŸ“‚ PDFã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"])
target_text = ""

with tab1:
    url_input = st.text_input("URLã‚’å…¥åŠ›", placeholder="https://example.com/article", label_visibility="collapsed")
    if url_input and st.button("URLã‚’åˆ†æã™ã‚‹"):
        with st.status("ğŸš€ å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã—ãŸ...", expanded=True) as status:
            try:
                target_text, _ = deep_dive_analysis(url_input, enable_deep_dive, max_links, status)
                status.update(label="æº–å‚™å®Œäº†ï¼AIãŒåˆ†æã‚’é–‹å§‹ã—ã¾ã™ã€‚", state="complete", expanded=False)
            except Exception as e:
                status.update(label="ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ", state="error")
                st.error(f"è©³ç´°: {e}")

with tab2:
    uploaded_pdf = st.file_uploader("PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["pdf"], label_visibility="collapsed")
    if uploaded_pdf and st.button("PDFã‚’åˆ†æã™ã‚‹"):
        with st.status("ğŸš€ å‡¦ç†ä¸­...", expanded=True) as status:
            try:
                status.write("PDFè§£æä¸­...")
                target_text = get_pdf_text_from_bytes(uploaded_pdf.getvalue())
                status.update(label="æº–å‚™å®Œäº†ï¼AIãŒåˆ†æã‚’é–‹å§‹ã—ã¾ã™ã€‚", state="complete", expanded=False)
            except Exception as e:
                status.update(label="ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ", state="error")
                st.error(f"è©³ç´°: {e}")

# --- AIå®Ÿè¡Œ ---

if target_text:
    # æ–‡å­—æ•°åˆ¶é™ (ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæº¢ã‚Œé˜²æ­¢)
    if len(target_text) > 20000:
        st.toast("âš ï¸ ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒé•·ã™ãã‚‹ãŸã‚ã€å…ˆé ­20,000æ–‡å­—ã®ã¿ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚", icon="âœ‚ï¸")
        target_text = target_text[:20000]

    llm = ChatOllama(
        model=MODEL_NAME,
        base_url=OLLAMA_URL,
        temperature=0.3,
        headers={"ngrok-skip-browser-warning": "true"},
        keep_alive="5m"
    )

    # å®‰å…¨ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ (æ³¢æ‹¬å¼§ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—)
    safe_user_prompt = escape_brackets(user_prompt)

    final_prompt = f"""
    {safe_user_prompt}

    ---
    ã€ãƒªãƒ³ã‚¯æƒ…å ±ã®æ‰±ã„ã«ã¤ã„ã¦ã€‘
    å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã«ã¯ã€Œãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã€ã¨ã€å ´åˆã«ã‚ˆã‚Šã€Œå‚è€ƒãƒªãƒ³ã‚¯ã€ãŒå«ã¾ã‚Œã¾ã™ã€‚
    - **ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„** ã®å†…å®¹ã‚’æ­£ã¨ã—ã¦æ‰±ã£ã¦ãã ã•ã„ã€‚
    - **å‚è€ƒãƒªãƒ³ã‚¯** ã®æƒ…å ±ã¯ã€ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ç†è§£ã‚’åŠ©ã‘ã‚‹ã€ã¾ãŸã¯è£œè¶³ã™ã‚‹ãŸã‚ã«ä¸å¯æ¬ ãªå ´åˆã®ã¿çµ±åˆã—ã¦ãã ã•ã„ã€‚

    ã€å‡ºåŠ›ãƒ«ãƒ¼ãƒ«ã€‘
    1. è¨€èªã¯ **æ—¥æœ¬èª** ã§å‡ºåŠ›ã™ã‚‹ã“ã¨ã€‚
    2. è¦‹å‡ºã—ã‚„ãƒªã‚¹ãƒˆã‚’æ´»ç”¨ã—ã€Markdownå½¢å¼ã§æ•´å½¢ã™ã‚‹ã“ã¨ã€‚
    3. **æ¯”è¼ƒã‚„ãƒ‡ãƒ¼ã‚¿ã¯Markdownã®è¡¨ï¼ˆTableï¼‰ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨**ï¼ˆUIå´ã§è¦‹ã‚„ã™ãè¡¨ç¤ºã•ã‚Œã¾ã™ï¼‰ã€‚
    4. é‡è¦ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¯ **å¤ªå­—** ã§å¼·èª¿ã™ã‚‹ã“ã¨ã€‚
    
    ã€å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã€‘
    {{content}}
    """

    prompt = ChatPromptTemplate.from_template(final_prompt)
    chain = prompt | llm | StrOutputParser()

    st.markdown("---")
    output_container = st.empty()
    full_response = ""

    try:
        for chunk in chain.stream({"content": target_text}):
            full_response += chunk
            output_container.markdown(full_response)
        
        st.markdown("---")
        st.caption("Markdownã‚½ãƒ¼ã‚¹ (ã‚³ãƒ”ãƒ¼ç”¨)")
        st.code(full_response, language="markdown")
        st.toast("åˆ†æå®Œäº†ï¼", icon="âœ…")

    except Exception as e:
        st.error(f"AIå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")

import streamlit as st
import os
import requests
import tempfile
from bs4 import BeautifulSoup
from urllib.parse import urljoin
from langchain_ollama import ChatOllama
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_community.document_loaders import PyPDFLoader

# --- è¨­å®š & å®šæ•° ---
OLLAMA_URL = st.secrets.get("OLLAMA_BASE_URL", "http://localhost:11435")
MODEL_NAME = st.secrets.get("MODEL_NAME", "nemotron-3-nano")

# --- Notioné¢¨ã‚¹ã‚¿ã‚¤ãƒ«è¨­å®š ---
st.set_page_config(
    page_title="Essence - AI Summary",
    page_icon="âœ¨",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ã‚«ã‚¹ã‚¿ãƒ CSS: Notioné¢¨ã®ãƒ€ãƒ¼ã‚¯ãªé›°å›²æ°—ã¨ãƒ•ã‚©ãƒ³ãƒˆèª¿æ•´
st.markdown("""
<style>
    .stApp {
        background-color: #191919;
        color: #e0e0e0;
    }
    h1, h2, h3 {
        font-family: 'Inter', sans-serif;
        color: #ffffff !important;
    }
    .stButton>button {
        background-color: #37352f;
        color: white;
        border: 1px solid #555;
        border-radius: 4px;
    }
    .stTextInput>div>div>input {
        background-color: #2f2f2f;
        color: white;
    }
    /* å¼•ç”¨ãƒ–ãƒ­ãƒƒã‚¯ã®ã‚¹ã‚¿ã‚¤ãƒ« */
    blockquote {
        background-color: #2f2f2f;
        border-left: 3px solid #d44c47;
        padding: 1rem;
        border-radius: 4px;
    }
</style>
""", unsafe_allow_html=True)

# --- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆé›† ---
PROMPT_TEMPLATES = {
    "ãƒ“ã‚¸ãƒã‚¹ãƒ»çµŒå–¶å±¤å‘ã‘ (æˆ¦ç•¥ãƒ»å½±éŸ¿)": """
ã‚ãªãŸã¯ãƒãƒƒã‚­ãƒ³ã‚¼ãƒ¼ã‚„BCGå‡ºèº«ã®æˆ¦ç•¥ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆAIã§ã™ã€‚
å…¥åŠ›ã•ã‚ŒãŸæƒ…å ±ã‚’ä»¥ä¸‹ã®è¦³ç‚¹ã§åˆ†æã—ã€æ„æ€æ±ºå®šã«å½¹ç«‹ã¤ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

1. **ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼**: 30ç§’ã§èª­ã‚ã‚‹è¦ç´„
2. **å¸‚å ´ãƒ»æ¥­ç•Œã¸ã®å½±éŸ¿**: ã“ã®æƒ…å ±ãŒãƒ“ã‚¸ãƒã‚¹ç’°å¢ƒã«ä¸ãˆã‚‹ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ
3. **é‡è¦æ•°å€¤ãƒ»KPI**: å£²ä¸Šã€æˆé•·ç‡ã€ã‚³ã‚¹ãƒˆå‰Šæ¸›åŠ¹æœãªã©ã®å…·ä½“çš„ãªæ•°å­—
4. **ãƒã‚¯ã‚¹ãƒˆã‚¢ã‚¯ã‚·ãƒ§ãƒ³**: çµŒå–¶å±¤ãŒæ¤œè¨ã™ã¹ãæ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

æ–‡ä½“ã¯ç°¡æ½”ã€æ–­å®šçš„ã€è«–ç†çš„ã«ã—ã¦ãã ã•ã„ã€‚
""",
    "ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒ»æŠ€è¡“è€…å‘ã‘ (å®Ÿè£…ãƒ»ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£)": """
ã‚ãªãŸã¯Googleã®ã‚·ãƒ‹ã‚¢ã‚¹ã‚¿ãƒƒãƒ•ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã§ã™ã€‚
å…¥åŠ›ã•ã‚ŒãŸæŠ€è¡“æ–‡æ›¸ã‚„è¨˜äº‹ã‹ã‚‰ã€ä»¥ä¸‹ã®æŠ€è¡“çš„æœ¬è³ªã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

1. **ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®è¦ç‚¹**: æ¡ç”¨ã•ã‚Œã¦ã„ã‚‹æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯ã€è¨­è¨ˆæ€æƒ³
2. **è§£æ±ºã•ã‚ŒãŸèª²é¡Œ**: ã©ã®ã‚ˆã†ãªæŠ€è¡“çš„è² å‚µã‚„ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ãŒè§£æ¶ˆã•ã‚ŒãŸã‹
3. **ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•**: ãƒ¡ãƒªãƒƒãƒˆã®è£ã«ã‚ã‚‹ãƒ‡ãƒ¡ãƒªãƒƒãƒˆã‚„åˆ¶ç´„äº‹é …
4. **ã‚³ãƒ¼ãƒ‰/å®Ÿè£…ã®ãƒ’ãƒ³ãƒˆ**: å®Ÿè£…æ™‚ã«æ³¨æ„ã™ã¹ãå…·ä½“çš„ãªãƒã‚¤ãƒ³ãƒˆ

æ–‡ä½“ã¯æŠ€è¡“ç”¨èªã‚’æ­£ç¢ºã«ä½¿ã„ã€ç®‡æ¡æ›¸ãã§æ§‹é€ åŒ–ã—ã¦ãã ã•ã„ã€‚
""",
    "ç ”ç©¶è€…ãƒ»ã‚¢ã‚«ãƒ‡ãƒŸã‚¢å‘ã‘ (æ‰‹æ³•ãƒ»æ–°è¦æ€§)": """
ã‚ãªãŸã¯ãƒˆãƒƒãƒ—ã‚¸ãƒ£ãƒ¼ãƒŠãƒ«ã®æŸ»èª­è€…ï¼ˆReviewerï¼‰ã§ã™ã€‚
å…¥åŠ›ã•ã‚ŒãŸè«–æ–‡ã‚„ãƒ¬ãƒãƒ¼ãƒˆã‚’ä»¥ä¸‹ã®å­¦è¡“çš„è¦³ç‚¹ã§åˆ†æã—ã¦ãã ã•ã„ã€‚

1. **ãƒªã‚µãƒ¼ãƒã‚¯ã‚¨ã‚¹ãƒãƒ§ãƒ³**: ä½•ã‚’è§£æ±ºã—ã‚ˆã†ã¨ã—ã¦ã„ã‚‹ã®ã‹
2. **ææ¡ˆæ‰‹æ³•ã®æ–°è¦æ€§**: æ—¢å­˜ç ”ç©¶ã¨ã®æ±ºå®šçš„ãªé•ã„ï¼ˆNoveltyï¼‰
3. **æ¤œè¨¼çµæœã¨é™ç•Œ**: å®Ÿé¨“çµæœã®å¦¥å½“æ€§ã¨ã€æ®‹ã•ã‚ŒãŸèª²é¡Œï¼ˆLimitationï¼‰
4. **åˆ†é‡ã¸ã®è²¢çŒ®**: ã“ã®çŸ¥è¦‹ãŒå­¦è¡“ç•Œã«ä¸ãˆã‚‹ç¤ºå”†

æ–‡ä½“ã¯ã‚¢ã‚«ãƒ‡ãƒŸãƒƒã‚¯ã‹ã¤å®¢è¦³çš„ã«ã—ã¦ãã ã•ã„ã€‚
""",
    "æ±ç”¨ãƒ»è©³ç´°è¦ç´„ (Deep Dive)": """
ã‚ãªãŸã¯å„ªç§€ãªè¦ç´„ç·¨é›†è€…ã§ã™ã€‚
å…¥åŠ›ã•ã‚ŒãŸæƒ…å ±ã‚’ã€èª°ãŒèª­ã‚“ã§ã‚‚ç†è§£ã§ãã‚‹ã‚ˆã†ã«è©³ç´°ã«æ§‹é€ åŒ–ã—ã¦ãã ã•ã„ã€‚

- å°‚é–€ç”¨èªã«ã¯ç°¡å˜ãªè£œè¶³ã‚’å…¥ã‚Œã‚‹ã“ã¨
- æŠ½è±¡çš„ãªæ¦‚å¿µã¯å…·ä½“ä¾‹ã«è½ã¨ã—è¾¼ã‚€ã“ã¨
- é‡è¦ãªäº‹å®Ÿã¯æ¼ã‚‰ã•ãšåˆ—æŒ™ã™ã‚‹ã“ã¨
"""
}

# --- ãƒ­ã‚¸ãƒƒã‚¯é–¢æ•°ç¾¤ ---

def get_pdf_text_from_url(url):
    """URLã‹ã‚‰PDFã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆåŒ–"""
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers, timeout=15)
        response.raise_for_status()
        
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
            tmp_file.write(response.content)
            tmp_path = tmp_file.name

        loader = PyPDFLoader(tmp_path)
        pages = loader.load()
        text = "\n".join([p.page_content for p in pages])
        
        os.remove(tmp_path)
        return text
    except Exception as e:
        return f"PDFå–å¾—ã‚¨ãƒ©ãƒ¼: {e}"

def get_content_from_url(url):
    """URLã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¿ã‚¤ãƒ—ã‚’åˆ¤å®šã—ã¦ãƒ†ã‚­ã‚¹ãƒˆåŒ–"""
    try:
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}
        
        # HEADãƒªã‚¯ã‚¨ã‚¹ãƒˆã§Content-Typeç¢ºèª
        try:
            head_resp = requests.head(url, headers=headers, timeout=5, allow_redirects=True)
            content_type = head_resp.headers.get('Content-Type', '').lower()
        except:
            content_type = ''

        # PDFåˆ¤å®š
        if 'application/pdf' in content_type or url.lower().endswith('.pdf'):
            st.toast("ğŸ“„ PDFã‚’æ¤œå‡ºã—ã¾ã—ãŸ", icon="â„¹ï¸")
            return get_pdf_text_from_url(url), "PDF Document"

        # HTMLåˆ¤å®š
        resp = requests.get(url, headers=headers, timeout=10)
        resp.raise_for_status()
        
        if 'application/pdf' in resp.headers.get('Content-Type', '').lower():
             st.toast("ğŸ“„ PDFã‚’æ¤œå‡ºã—ã¾ã—ãŸ(Redirect)", icon="â„¹ï¸")
             return get_pdf_text_from_url(url), "PDF Document"

        soup = BeautifulSoup(resp.content, 'html.parser')
        for tag in soup(['nav', 'header', 'footer', 'script', 'style', 'aside', 'form', 'noscript']):
            tag.decompose()

        main_content = soup.find('main') or soup.find('article') or soup.find('div', class_='content') or soup.body
        if not main_content:
            return "", "Unknown"

        text = main_content.get_text(separator="\n", strip=True)
        return text, soup.title.string if soup.title else "No Title"

    except Exception as e:
        return f"ã‚¨ãƒ©ãƒ¼: {e}", "Error"

def process_uploaded_pdf(uploaded_file):
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
            tmp_file.write(uploaded_file.getvalue())
            tmp_path = tmp_file.name

        loader = PyPDFLoader(tmp_path)
        pages = loader.load()
        text = "\n".join([p.page_content for p in pages])
        os.remove(tmp_path)
        return text
    except Exception as e:
        return f"ã‚¨ãƒ©ãƒ¼: {e}"

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š ---
with st.sidebar:
    st.title("âœ¨ Essence")
    st.caption("Context-Aware AI Summarizer")
    
    st.markdown("---")
    
    # 1. å…¥åŠ›ã‚½ãƒ¼ã‚¹
    input_mode = st.radio("Input Source", ["Web URL / PDF URL", "PDF Upload"], label_visibility="collapsed")
    
    st.markdown("---")
    
    # 2. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé¸æŠ
    st.subheader("ğŸ›  Settings")
    selected_template_name = st.selectbox(
        "Target Persona",
        options=list(PROMPT_TEMPLATES.keys()),
        index=0
    )
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç·¨é›†ã‚¨ãƒªã‚¢ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ã‚»ãƒƒãƒˆï¼‰
    user_system_prompt = st.text_area(
        "Custom Instructions",
        value=PROMPT_TEMPLATES[selected_template_name],
        height=200,
        help="AIã¸ã®æŒ‡ç¤ºã‚’è‡ªç”±ã«ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã§ãã¾ã™"
    )

# --- ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢ ---

st.title("Essence")
st.markdown("#### æœ¬è³ªã‚’ã€æŠ½å‡ºã™ã‚‹ã€‚")

target_text = ""
source_title = ""

# å…¥åŠ›UI
if input_mode == "Web URL / PDF URL":
    url_input = st.text_input("", placeholder="https://example.com/article_or_report.pdf", label_visibility="collapsed")
    if url_input and st.button("Analyze", type="primary"):
        with st.spinner("Fetching content..."):
            target_text, source_title = get_content_from_url(url_input)

elif input_mode == "PDF Upload":
    uploaded_file = st.file_uploader("", type=["pdf"], label_visibility="collapsed")
    if uploaded_file and st.button("Analyze", type="primary"):
        with st.spinner("Reading PDF..."):
            target_text = process_uploaded_pdf(uploaded_file)
            source_title = uploaded_file.name

# AIè§£æå®Ÿè¡Œ
if target_text:
    # ã‚¨ãƒ©ãƒ¼åˆ¤å®š
    if target_text.startswith("ã‚¨ãƒ©ãƒ¼") or target_text.startswith("PDFå–å¾—ã‚¨ãƒ©ãƒ¼"):
        st.error(target_text)
    else:
        # æ–‡å­—æ•°åˆ¶é™ã¨è­¦å‘Š
        if len(target_text) > 25000:
            st.warning(f"âš ï¸ ãƒ†ã‚­ã‚¹ãƒˆãŒé•·å¤§ã§ã™ï¼ˆ{len(target_text)}æ–‡å­—ï¼‰ã€‚ç²¾åº¦ç¶­æŒã®ãŸã‚å…ˆé ­25,000æ–‡å­—ã‚’åˆ†æå¯¾è±¡ã¨ã—ã¾ã™ã€‚")
            target_text = target_text[:25000]

        # LLMè¨­å®š
        llm = ChatOllama(
            model=MODEL_NAME,
            base_url=OLLAMA_URL,
            temperature=0.3, # åˆ†æã®ç²¾åº¦é‡è¦–
            headers={"ngrok-skip-browser-warning": "true"},
            keep_alive="5m"
        )

        # æœ€çµ‚çš„ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®çµ„ã¿ç«‹ã¦
        # Chain of Thought (æ€è€ƒã®é€£é–) ã‚’ä¿ƒã™æŒ‡ç¤ºã‚’è¿½åŠ 
        final_prompt_template = f"""
        {user_system_prompt}
        
        ---
        ã€ä»¥ä¸‹ã®æ‰‹é †ã§å‡¦ç†ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‘
        1. ã¾ãšã€å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆå…¨ä½“ã‚’èª­ã¿ã€æ–‡è„ˆã¨æ§‹é€ ã‚’ç†è§£ã™ã‚‹ã€‚
        2. é‡è¦ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€æ•°å€¤ã€ä¸»å¼µã‚’æŠ½å‡ºã™ã‚‹ã€‚
        3. ä¸Šè¨˜ã®ã€Œã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒšãƒ«ã‚½ãƒŠã€ã®è¦–ç‚¹ã§ã€æƒ…å ±ã‚’å†æ§‹æˆã™ã‚‹ã€‚
        4. ä»¥ä¸‹ã®å½¢å¼ã®Markdownã§å‡ºåŠ›ã™ã‚‹ã€‚

        # (ã“ã“ã«å†…å®¹ã«åŸºã¥ã„ãŸé­…åŠ›çš„ãªã‚¿ã‚¤ãƒˆãƒ«)
        
        ## ğŸ’¡ Essence (æœ¬è³ªçš„è¦ç´„)
        (ã“ã“ã«æ ¸å¿ƒã¨ãªã‚‹è¦ç´„ã‚’è¨˜è¿°)

        ## ğŸ·ï¸ Tags
        (é–¢é€£ã™ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°å½¢å¼ã§5ã¤ #AI #Tech ç­‰)

        ---
        
        (ä»¥ä¸‹ã€ãƒšãƒ«ã‚½ãƒŠã”ã¨ã®è¦æ±‚é …ç›®ã‚’å‡ºåŠ›)

        ---
        
        ã€å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã€‘
        {{content}}
        """

        prompt = ChatPromptTemplate.from_template(final_prompt_template)
        chain = prompt | llm | StrOutputParser()

        st.markdown("---")
        st.subheader("Result")
        
        # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¡¨ç¤º
        result_container = st.empty()
        full_response = ""
        
        try:
            for chunk in chain.stream({"content": target_text}):
                full_response += chunk
                result_container.markdown(full_response)
            
            # å®Œäº†å¾Œã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¨ãƒªã‚¢
            st.markdown("---")
            col1, col2 = st.columns([1, 4])
            with col1:
                st.success("Analysis Complete")
            with col2:
                # ã‚³ãƒ”ãƒ¼ç”¨ã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ï¼ˆNotionè²¼ã‚Šä»˜ã‘ç”¨ï¼‰
                st.expander("Copy Markdown Source").code(full_response, language="markdown")
                
        except Exception as e:
            st.error(f"AI Processing Error: {e}")
